{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 初期設定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ライブラリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import log_loss\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# チューニンング方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## グリッドサーチ/ランダムサーチ\n",
    "- ランダムサーチの方が効率が良い by Bergstra and Bengio  \n",
    "\n",
    " ![Grid or Random](/Users/nozawayuta/GitHub/kagglebook/misc/gridrandom.png \"Grid or Random\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#パラメータ1,パラメータ2の候補\n",
    "param1_list = [3, 5, 7, 9]\n",
    "param2_list = [1, 2, 3, 4, 5]\n",
    "\n",
    "# グリッドサーチで探索するパラメータの組み合わせ\n",
    "grid_search_params = []\n",
    "for p1 in param1_list:\n",
    "    for p2 in param2_list:\n",
    "        grid_search_params.append((p1, p2))\n",
    "\n",
    "# ランダムサーチで探索するパラメータの組み合わせ\n",
    "random_search_params = []\n",
    "trials = 15\n",
    "for i in range(trials):\n",
    "    p1 = np.random.choice(param1_list)\n",
    "    p2 = np.random.choice(param2_list)\n",
    "    random_search_params.append((p1, p2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ベイズ最適化 Bayesian Optimization  \n",
    "- 過去の探索から誤差を読み取り精度の高いパラメータに近づけていく考え方  \n",
    "- hyperoptライブラリが比較的よく使われる \n",
    "- その他ライブラリ   \n",
    "    - optuna\n",
    "    - gpyopt  \n",
    "    - spearmint  \n",
    "    - sckit-optimize\n",
    "- パラメタ調整フロー  \n",
    "    1. ベースラインとなるパラメータで学習\n",
    "    1. 1-3種類, 2-5候補で**グリッドサーチ**を行う\n",
    "    1. 本格的にパラメータチューニングを行う場合には**ベイズ最適化**を使う\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperopt\n",
    "- TPE(Tree-structured Parzen Estimator)アルゴリズムを使用\n",
    "- 設定内容\n",
    "    - 最小化したい評価指標の指定\n",
    "        - accuracyなど高い方が良い評価指標の際には正負を反転させる必要有り\n",
    "    - 探索するパラメータの範囲の定義\n",
    "        - 事前分布の定義\n",
    "            - 一様分布（決定木の深さ）\n",
    "     - 探索回数の指定\n",
    "        - 目安は100回程度\n",
    "- 撮り得るパラメータの組み合わせの集合を**パラメータ空間**という"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "\n",
    "    def __init__(self, params=None):\n",
    "        self.model = None\n",
    "        if params is None:\n",
    "            self.params = {}\n",
    "        else:\n",
    "            self.params = params\n",
    "\n",
    "    def fit(self, tr_x, tr_y, va_x, va_y):\n",
    "        params = {'objective': 'binary:logistic', 'silent': 1, 'random_state': 71}\n",
    "        params.update(self.params)\n",
    "        num_round = 10\n",
    "        dtrain = xgb.DMatrix(tr_x, label=tr_y)\n",
    "        dvalid = xgb.DMatrix(va_x, label=va_y)\n",
    "        watchlist = [(dtrain, 'train'), (dvalid, 'eval')]\n",
    "        self.model = xgb.train(params, dtrain, num_round, evals=watchlist)\n",
    "\n",
    "    def predict(self, x):\n",
    "        data = xgb.DMatrix(x)\n",
    "        pred = self.model.predict(data)\n",
    "        return pred\n",
    "\n",
    "\n",
    "from hyperopt import hp\n",
    "\n",
    "space = {\n",
    "    'activation': hp.choice('activation', ['prelu', 'relu']),\n",
    "    'dropout': hp.uniform('dropout', 0, 0.2),\n",
    "    'units': hp.quniform('units', 32, 256, 32),\n",
    "    'learning_rate': hp.loguniform('learning_rate', np.log(0.00001), np.log(0.01)),\n",
    "}\n",
    "\n",
    "# -----------------------------------\n",
    "# hyperoptを使ったパラメータ探索\n",
    "# -----------------------------------\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# 最小化したい評価指標のスコアを返す関数を作成する\n",
    "## validationに対して推論して評価指標のスコアを計算する処理を行う\n",
    "def score(params):\n",
    "    # パラメータを与えたときに最小化する評価指標を指定する\n",
    "    # 具体的には、モデルにパラメータを指定して学習・予測させた場合のスコアを返すようにする\n",
    "\n",
    "    # max_depthの型を整数型に修正する\n",
    "    params['max_depth'] = int(params['max_depth'])\n",
    "\n",
    "    # Modelクラスを定義しているものとする\n",
    "    # Modelクラスは、fitで学習し、predictで予測値の確率を出力する\n",
    "    model = Model(params)\n",
    "    model.fit(tr_x, tr_y, va_x, va_y)\n",
    "    va_pred = model.predict(va_x)\n",
    "    score = log_loss(va_y, va_pred)\n",
    "    print(f'params: {params}, logloss: {score:.4f}')\n",
    "\n",
    "    # 情報を記録しておく\n",
    "    history.append((params, score))\n",
    "\n",
    "    return {'loss': score, 'status': STATUS_OK}\n",
    "\n",
    "\n",
    "# 探索するパラメータの空間を指定する\n",
    "space = {\n",
    "    'min_child_weight': hp.quniform('min_child_weight', 1, 5, 1),\n",
    "    'max_depth': hp.quniform('max_depth', 3, 9, 1),\n",
    "    'gamma': hp.quniform('gamma', 0, 0.4, 0.1),\n",
    "}\n",
    "\n",
    "# hyperoptによるパラメータ探索の実行\n",
    "max_evals = 10\n",
    "trials = Trials()\n",
    "history = []\n",
    "# 作成した関数、パラメータ空間、アルゴリズム、Trials(), 探索回数(max_evals)をしてすることで探索開始\n",
    "fmin(score, space, algo=tpe.suggest, trials=trials, max_evals=max_evals)\n",
    "\n",
    "# 記録した情報からパラメータとスコアを出力する\n",
    "# （trialsからも情報が取得できるが、パラメータの取得がやや行いづらいため）\n",
    "history = sorted(history, key=lambda tpl: tpl[1])\n",
    "best = history[0]\n",
    "print(f'best params:{best[0]}, score:{best[1]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optuna\n",
    "- アルゴリズムはTPE（hyperoptと同様）\n",
    "- APIが使いやすくなっている→効率的なチューニングができる\n",
    "    - Define-by-Run\n",
    "        - パラメータ空間を別途定義するhyperoptと異なり、モデル記述の中で定義、決定する\n",
    "    - 学習曲線を用いた試行の枝刈り\n",
    "    - 並列分散最適化\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDTパラメータとチューニング\n",
    " ![param](/Users/nozawayuta/GitHub/kagglebook/misc/xgboost_param.png \"param\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7869b2d4adbdba87f1fcd45cdf0956132ee598d480d8ef1fb6f8c9150ab38877"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
